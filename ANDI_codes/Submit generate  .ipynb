{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41648fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:12:24.705449Z",
     "start_time": "2024-07-19T05:12:24.513917Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"ANDI_DATA/challenge_data.pkl\", \"rb\") as f:\n",
    "    challenge_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786da534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:12:25.133455Z",
     "start_time": "2024-07-19T05:12:25.121257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length of data = 200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "length = []\n",
    "\n",
    "for exp in range(12):\n",
    "    for fov in range(30):\n",
    "        for n in range(len(challenge_data[exp][fov])):\n",
    "            length.append(len(challenge_data[exp][fov][0][n]))\n",
    "            \n",
    "print('max_length of data = {}'.format(np.max(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1223841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:12:25.752472Z",
     "start_time": "2024-07-19T05:12:25.744242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "for exp in range(12):\n",
    "    print(len(challenge_data[exp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb502c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:12:27.514008Z",
     "start_time": "2024-07-19T05:12:27.489588Z"
    }
   },
   "outputs": [],
   "source": [
    "def TMSD(traj, t_lags):\n",
    "    ttt = np.zeros_like(t_lags, dtype= float)\n",
    "    for idx, t in enumerate(t_lags): \n",
    "        for p in range(len(traj)-t):\n",
    "            ttt[idx] += (traj[p]-traj[p+t])**2            \n",
    "        ttt[idx] /= len(traj)-t    \n",
    "    return ttt\n",
    "\n",
    "def ta_msd(data_x,data_y):\n",
    "    TA_MSD = []\n",
    "    lag = len(data_x) \n",
    "    for i,s in enumerate(range(1,lag)):\n",
    "        tamsd_s = []\n",
    "        for t in range(len(data_x) - s):\n",
    "            tamsd_s.append(((data_x[t+s] - data_x[t])**2) + ((data_y[t+s] - data_y[t])**2))\n",
    "        TA_MSD.append(np.asarray(np.sum(tamsd_s)/len(tamsd_s)))\n",
    "\n",
    "    return np.asarray(TA_MSD)\n",
    "\n",
    "def correlation(x,y):\n",
    "    \n",
    "    T = int(len(x) - 2)\n",
    "    \n",
    "    cor = np.zeros(T)\n",
    "    for t in range(T):\n",
    "        dx_1 = x[t+1] - x[t]\n",
    "        dx_2 = x[t+2] - x[t+1]\n",
    "        \n",
    "        dy_1 = y[t+1] - y[t]\n",
    "        dy_2 = y[t+2] - y[t+1]\n",
    "        \n",
    "        cor[t] = (dx_1*dx_2 + dy_1*dy_2)\n",
    "    \n",
    "    return np.mean(cor)\n",
    "\n",
    "\n",
    "\n",
    "def feature_v2(xtrace,ytrace):\n",
    "    \n",
    "    traces = np.sqrt(xtrace**2 + ytrace**2)\n",
    "    \n",
    "    mean = np.mean(traces)    \n",
    "    ms = np.std(traces) \n",
    "\n",
    "\n",
    "   \n",
    "    vtraces = np.diff(traces)\n",
    "    \n",
    "    v = np.abs(vtraces)\n",
    "    vmean = np.mean(v) \n",
    "    vms = np.std(v) \n",
    "\n",
    "    \n",
    "    corr = correlation(xtrace,ytrace)\n",
    "#     r = np.abs(np.diff(np.sqrt(xtrace**2 + ytrace**2)))\n",
    "    r = traces\n",
    "    f1 = np.max(r) - np.min(r) \n",
    "    f2 = np.max(v) - np.min(v) \n",
    "    \n",
    "       \n",
    "    tlag = np.linspace(1, len(traces)-1, 9, dtype = 'int')\n",
    "    \n",
    "    msd = TMSD(traces, tlag)\n",
    "    A = np.vstack([np.log(tlag), np.ones(len(np.log(tlag)))]).T\n",
    "    nw1, nw0 = np.linalg.lstsq(A, np.log(msd), rcond=None)[0]\n",
    "\n",
    "\n",
    "    feature = np.asarray([mean, ms, vmean, vms, np.exp(nw0)/4,f1,f2, corr]) \n",
    "\n",
    "\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a76175",
   "metadata": {},
   "source": [
    "challenge_data = [exp][fov][x,y,z][index][t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff76cf27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:12:28.694904Z",
     "start_time": "2024-07-19T05:12:28.688841Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_close_elements(input_list):\n",
    "    i = 0\n",
    "    while i < len(input_list) - 1:\n",
    "        if input_list[i+1] - input_list[i] < 3:\n",
    "            input_list.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4993d0ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:12:29.487568Z",
     "start_time": "2024-07-19T05:12:29.312167Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load feature_data of challenge_data\n",
    "\n",
    "with open('ANDI_DATA/feature_data (challenge_feature_v2_array).pkl', 'rb') as f:\n",
    "    feature_data = pickle.load(f)\n",
    "    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdba2de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:13:13.705894Z",
     "start_time": "2024-07-19T05:12:29.985102Z"
    },
    "code_folding": [
     4,
     20
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 calculating..\n",
      "1 calculating..\n",
      "2 calculating..\n",
      "3 calculating..\n",
      "4 calculating..\n",
      "5 calculating..\n",
      "6 calculating..\n",
      "7 calculating..\n",
      "8 calculating..\n",
      "9 calculating..\n",
      "10 calculating..\n",
      "11 calculating..\n",
      "0 calculating..\n",
      "1 calculating..\n",
      "2 calculating..\n",
      "3 calculating..\n",
      "4 calculating..\n",
      "5 calculating..\n",
      "6 calculating..\n",
      "7 calculating..\n",
      "8 calculating..\n",
      "9 calculating..\n",
      "10 calculating..\n",
      "11 calculating..\n"
     ]
    }
   ],
   "source": [
    "# calculate model input\n",
    "\n",
    "from tensorflow import reduce_sum\n",
    "\n",
    "def weighted_sum_data_k(\n",
    "    data,\n",
    "    coefficients: list = [0, 0, 1, 0, 1, 0, 0, 0]\n",
    "):\n",
    "\n",
    "    for idx, coefficient in enumerate(coefficients):\n",
    "        data[..., idx] = data[..., idx] * coefficient\n",
    "\n",
    "    data = reduce_sum(\n",
    "        data,\n",
    "        axis=len(data.shape) - 1,\n",
    "        keepdims=True\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "def weighted_sum_data_alpha(\n",
    "    data,\n",
    "    coefficients: list = [1, 1, 1, 1, 1, 1, 1, 1]\n",
    "):\n",
    "\n",
    "    for idx, coefficient in enumerate(coefficients):\n",
    "        data[..., idx] = data[..., idx] * coefficient\n",
    "\n",
    "    data = reduce_sum(\n",
    "        data,\n",
    "        axis=len(data.shape) - 1,\n",
    "        keepdims=True\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data_alpha = {}\n",
    "test_data_k = {}\n",
    "for exp in range(12):\n",
    "    print('{} calculating..'.format(exp))\n",
    "    test_data_k_exp = {}\n",
    "    for fov in range(30):\n",
    "        with open('ANDI_DATA/feature_data (challenge_feature_v2_array).pkl', 'rb') as f:\n",
    "            feature_data = pickle.load(f)\n",
    "        test_data_k_exp[fov] =  weighted_sum_data_k(feature_data[exp][fov])\n",
    "    test_data_k[exp] = test_data_k_exp\n",
    "    \n",
    "for exp in range(12):\n",
    "    print('{} calculating..'.format(exp))\n",
    "    test_data_alpha_exp = {}\n",
    "    for fov in range(30):\n",
    "        with open('ANDI_DATA/feature_data (challenge_feature_v2_array).pkl', 'rb') as f:\n",
    "            feature_data = pickle.load(f)\n",
    "        test_data_alpha_exp[fov] =  weighted_sum_data_alpha(feature_data[exp][fov])\n",
    "    test_data_alpha[exp] = test_data_alpha_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f74522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:13:14.225290Z",
     "start_time": "2024-07-19T05:13:13.707744Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('ANDI_DATA/alpha_input (challenge_feature_v2_array).pkl', 'wb') as f:\n",
    "    pickle.dump(test_data_alpha, f)\n",
    "    \n",
    "with open('ANDI_DATA/k_input (challenge_feature_v2_array).pkl', 'wb') as f:\n",
    "    pickle.dump(test_data_k, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df1a25cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:13:14.282743Z",
     "start_time": "2024-07-19T05:13:14.229852Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('ANDI_DATA/alpha_input (challenge_feature_v2_array).pkl', 'rb') as f:\n",
    "    alpha_input = pickle.load(f)\n",
    "    \n",
    "with open('ANDI_DATA/k_input (challenge_feature_v2_array).pkl', 'rb') as f:\n",
    "    k_input = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47e10e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:13:14.460504Z",
     "start_time": "2024-07-19T05:13:14.456694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(alpha_input))\n",
    "print(len(k_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d732e200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:13:33.501536Z",
     "start_time": "2024-07-19T05:13:14.462027Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "model_alpha = keras.models.load_model('models/predict_alpha.hdf5')\n",
    "model_k = keras.models.load_model('models/predict_k.hdf5')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7137720c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:13:33.507346Z",
     "start_time": "2024-07-19T05:13:33.504376Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_close_elements(input_list):\n",
    "    i = 0\n",
    "    while i < len(input_list) - 1:\n",
    "        if input_list[i+1] - input_list[i] < 3:\n",
    "            input_list.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "037a7f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:13:33.526014Z",
     "start_time": "2024-07-19T05:13:33.509010Z"
    }
   },
   "outputs": [],
   "source": [
    "# consider alpha and k\n",
    "\n",
    "def cpd_v1_two_side(alpha,k,T,Th_alpha,Th_k, end_index):\n",
    "    \n",
    "    pred_cp = []\n",
    "    reconstructed_feature1 = alpha[:int(T-end_index)]\n",
    "    reconstructed_feature2 = k[:int(T-end_index)]\n",
    "    T_length = T\n",
    "\n",
    "    alpha_diff_max = np.max(np.abs(np.diff(reconstructed_feature1)))\n",
    "    k_diff_max = np.max(np.abs(np.diff(reconstructed_feature2)))\n",
    "\n",
    "    if alpha_diff_max > Th_alpha or k_diff_max > Th_k:\n",
    "        if alpha_diff_max > k_diff_max:\n",
    "            delta_feature = np.abs(np.diff(alpha))\n",
    "            anomaly_index = 0\n",
    "            anomaly_zip = []\n",
    "            for n_zip in range(67):\n",
    "                anomaly_zip.append([])\n",
    "\n",
    "\n",
    "            for t, data_t in enumerate(delta_feature[:-1]):\n",
    "                if data_t > Th_alpha:\n",
    "                    anomaly_zip[anomaly_index].append((t,data_t))\n",
    "                    if delta_feature[t + 1] <= Th_alpha:\n",
    "                        anomaly_value = []\n",
    "                        for a_index in range(len(anomaly_zip[anomaly_index])):\n",
    "                            anomaly_value.append(anomaly_zip[anomaly_index][a_index][1])\n",
    "\n",
    "                        max_anomaly_index = np.argmax(anomaly_value)\n",
    "                        if (anomaly_zip[anomaly_index][max_anomaly_index][0] + 1) <= T:\n",
    "                            pred_cp.append(anomaly_zip[anomaly_index][max_anomaly_index][0] + 1)\n",
    "\n",
    "                        anomaly_index += 1\n",
    "                        \n",
    "        elif alpha_diff_max < k_diff_max:\n",
    "            delta_feature = np.abs(np.diff(k))\n",
    "            anomaly_index = 0\n",
    "            anomaly_zip = []\n",
    "            for n_zip in range(67):\n",
    "                anomaly_zip.append([])\n",
    "\n",
    "\n",
    "            for t, data_t in enumerate(delta_feature[:-1]):\n",
    "                if data_t > Th_k:\n",
    "                    anomaly_zip[anomaly_index].append((t,data_t))\n",
    "                    if delta_feature[t + 1] <= Th_k:\n",
    "                        anomaly_value = []\n",
    "                        for a_index in range(len(anomaly_zip[anomaly_index])):\n",
    "                            anomaly_value.append(anomaly_zip[anomaly_index][a_index][1])\n",
    "\n",
    "                        max_anomaly_index = np.argmax(anomaly_value)\n",
    "                        \n",
    "                        if (anomaly_zip[anomaly_index][max_anomaly_index][0] + 1) <= T:\n",
    "                            pred_cp.append(anomaly_zip[anomaly_index][max_anomaly_index][0] + 1)\n",
    "                        anomaly_index += 1\n",
    "\n",
    "        pred_cp.append(T)\n",
    "\n",
    "    elif alpha_diff_max <= Th_alpha and k_diff_max <= Th_k:\n",
    "        pred_cp.append(T)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    pred_cp = remove_close_elements(pred_cp)\n",
    "    return pred_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9087999b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:13:33.540914Z",
     "start_time": "2024-07-19T05:13:33.527630Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# perform andi-challene2 tasks\n",
    "\n",
    "def final_submit(feature_alpha,feature_k, model_alpha, model_k, data, Th_alpha, Th_k,end_index):\n",
    "\n",
    "    predicted_n = []\n",
    "\n",
    "    predicted_n.append(n)\n",
    "\n",
    "    alpha_data = np.zeros((200))\n",
    "    k_data = np.zeros((200))\n",
    "            \n",
    "    T_length = len(data)\n",
    "\n",
    "\n",
    "                \n",
    "    alpha = model_alpha.predict(feature_alpha)[0]\n",
    "    k = model_k.predict(feature_k)[0]\n",
    "        \n",
    "    pred_cp = cpd_v1_two_side(alpha,k,T_length,Th_alpha,Th_k, end_index)\n",
    "\n",
    "    if len(pred_cp) > 1:\n",
    "        pred_cp.insert(0,0)\n",
    "        for cp_num in range(int(len(pred_cp) - 1)):\n",
    "            x = data[pred_cp[cp_num]: pred_cp[cp_num+1]] \n",
    "            y = data[pred_cp[cp_num]: pred_cp[cp_num+1]] \n",
    "\n",
    "            predicted_alpha = np.mean(alpha[int(pred_cp[cp_num]+1): int(pred_cp[cp_num+1]-1)])\n",
    "            predicted_k = np.mean(k[int(pred_cp[cp_num]+1): int(pred_cp[cp_num+1]-1)])\n",
    "\n",
    "            if predicted_alpha >= 1.9:\n",
    "                model_label = 3\n",
    "\n",
    "            elif predicted_alpha < 0.05 and predicted_k < 0.05:\n",
    "                model_label = 0\n",
    "                \n",
    "            elif 0.95 <= predicted_alpha <= 1.05:\n",
    "                model_label = 1\n",
    "\n",
    "            else:\n",
    "                model_label = 2\n",
    "\n",
    "\n",
    "            predicted_n.append(predicted_k)\n",
    "            predicted_n.append(predicted_alpha)\n",
    "            predicted_n.append(model_label)\n",
    "            predicted_n.append(pred_cp[cp_num+1])\n",
    "                    \n",
    "                    \n",
    "    elif len(pred_cp) == 1:\n",
    "\n",
    "        predict_cp = [0]\n",
    "        predict_cp.append(pred_cp[0])\n",
    "\n",
    "\n",
    "        for cp_num in range(int(len(predict_cp) - 1)):\n",
    "\n",
    "\n",
    "            predicted_alpha = np.mean(alpha[int(predict_cp[cp_num]+1): int(predict_cp[cp_num+1]-1)])\n",
    "            predicted_k = np.mean(k[int(predict_cp[cp_num]+1): int(predict_cp[cp_num+1]-1)])\n",
    "\n",
    "  \n",
    "            if predicted_alpha >= 1.9:\n",
    "                model_label = 3\n",
    "    \n",
    "                        \n",
    "            else:\n",
    "                model_label = 2\n",
    "\n",
    "\n",
    "            predicted_n.append(predicted_k)\n",
    "            predicted_n.append(predicted_alpha)\n",
    "            predicted_n.append(model_label)\n",
    "            predicted_n.append(predict_cp[cp_num+1])\n",
    "    return predicted_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00c57220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:48:48.698012Z",
     "start_time": "2024-07-19T05:13:45.620285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0 calculating..\n",
      "0, 1 calculating..\n",
      "0, 2 calculating..\n",
      "0, 3 calculating..\n",
      "0, 4 calculating..\n",
      "0, 5 calculating..\n",
      "0, 6 calculating..\n",
      "0, 7 calculating..\n",
      "0, 8 calculating..\n",
      "0, 9 calculating..\n",
      "0, 10 calculating..\n",
      "0, 11 calculating..\n",
      "0, 12 calculating..\n",
      "0, 13 calculating..\n",
      "0, 14 calculating..\n",
      "0, 15 calculating..\n",
      "0, 16 calculating..\n",
      "0, 17 calculating..\n",
      "0, 18 calculating..\n",
      "0, 19 calculating..\n",
      "0, 20 calculating..\n",
      "0, 21 calculating..\n",
      "0, 22 calculating..\n",
      "0, 23 calculating..\n",
      "0, 24 calculating..\n",
      "0, 25 calculating..\n",
      "0, 26 calculating..\n",
      "0, 27 calculating..\n",
      "0, 28 calculating..\n",
      "0, 29 calculating..\n",
      "1, 0 calculating..\n",
      "1, 1 calculating..\n",
      "1, 2 calculating..\n",
      "1, 3 calculating..\n",
      "1, 4 calculating..\n",
      "1, 5 calculating..\n",
      "1, 6 calculating..\n",
      "1, 7 calculating..\n",
      "1, 8 calculating..\n",
      "1, 9 calculating..\n",
      "1, 10 calculating..\n",
      "1, 11 calculating..\n",
      "1, 12 calculating..\n",
      "1, 13 calculating..\n",
      "1, 14 calculating..\n",
      "1, 15 calculating..\n",
      "1, 16 calculating..\n",
      "1, 17 calculating..\n",
      "1, 18 calculating..\n",
      "1, 19 calculating..\n",
      "1, 20 calculating..\n",
      "1, 21 calculating..\n",
      "1, 22 calculating..\n",
      "1, 23 calculating..\n",
      "1, 24 calculating..\n",
      "1, 25 calculating..\n",
      "1, 26 calculating..\n",
      "1, 27 calculating..\n",
      "1, 28 calculating..\n",
      "1, 29 calculating..\n",
      "2, 0 calculating..\n",
      "2, 1 calculating..\n",
      "2, 2 calculating..\n",
      "2, 3 calculating..\n",
      "2, 4 calculating..\n",
      "2, 5 calculating..\n",
      "2, 6 calculating..\n",
      "2, 7 calculating..\n",
      "2, 8 calculating..\n",
      "2, 9 calculating..\n",
      "2, 10 calculating..\n",
      "2, 11 calculating..\n",
      "2, 12 calculating..\n",
      "2, 13 calculating..\n",
      "2, 14 calculating..\n",
      "2, 15 calculating..\n",
      "2, 16 calculating..\n",
      "2, 17 calculating..\n",
      "2, 18 calculating..\n",
      "2, 19 calculating..\n",
      "2, 20 calculating..\n",
      "2, 21 calculating..\n",
      "2, 22 calculating..\n",
      "2, 23 calculating..\n",
      "2, 24 calculating..\n",
      "2, 25 calculating..\n",
      "2, 26 calculating..\n",
      "2, 27 calculating..\n",
      "2, 28 calculating..\n",
      "2, 29 calculating..\n",
      "3, 0 calculating..\n",
      "3, 1 calculating..\n",
      "3, 2 calculating..\n",
      "3, 3 calculating..\n",
      "3, 4 calculating..\n",
      "3, 5 calculating..\n",
      "3, 6 calculating..\n",
      "3, 7 calculating..\n",
      "3, 8 calculating..\n",
      "3, 9 calculating..\n",
      "3, 10 calculating..\n",
      "3, 11 calculating..\n",
      "3, 12 calculating..\n",
      "3, 13 calculating..\n",
      "3, 14 calculating..\n",
      "3, 15 calculating..\n",
      "3, 16 calculating..\n",
      "3, 17 calculating..\n",
      "3, 18 calculating..\n",
      "3, 19 calculating..\n",
      "3, 20 calculating..\n",
      "3, 21 calculating..\n",
      "3, 22 calculating..\n",
      "3, 23 calculating..\n",
      "3, 24 calculating..\n",
      "3, 25 calculating..\n",
      "3, 26 calculating..\n",
      "3, 27 calculating..\n",
      "3, 28 calculating..\n",
      "3, 29 calculating..\n",
      "4, 0 calculating..\n",
      "4, 1 calculating..\n",
      "4, 2 calculating..\n",
      "4, 3 calculating..\n",
      "4, 4 calculating..\n",
      "4, 5 calculating..\n",
      "4, 6 calculating..\n",
      "4, 7 calculating..\n",
      "4, 8 calculating..\n",
      "4, 9 calculating..\n",
      "4, 10 calculating..\n",
      "4, 11 calculating..\n",
      "4, 12 calculating..\n",
      "4, 13 calculating..\n",
      "4, 14 calculating..\n",
      "4, 15 calculating..\n",
      "4, 16 calculating..\n",
      "4, 17 calculating..\n",
      "4, 18 calculating..\n",
      "4, 19 calculating..\n",
      "4, 20 calculating..\n",
      "4, 21 calculating..\n",
      "4, 22 calculating..\n",
      "4, 23 calculating..\n",
      "4, 24 calculating..\n",
      "4, 25 calculating..\n",
      "4, 26 calculating..\n",
      "4, 27 calculating..\n",
      "4, 28 calculating..\n",
      "4, 29 calculating..\n",
      "5, 0 calculating..\n",
      "5, 1 calculating..\n",
      "5, 2 calculating..\n",
      "5, 3 calculating..\n",
      "5, 4 calculating..\n",
      "5, 5 calculating..\n",
      "5, 6 calculating..\n",
      "5, 7 calculating..\n",
      "5, 8 calculating..\n",
      "5, 9 calculating..\n",
      "5, 10 calculating..\n",
      "5, 11 calculating..\n",
      "5, 12 calculating..\n",
      "5, 13 calculating..\n",
      "5, 14 calculating..\n",
      "5, 15 calculating..\n",
      "5, 16 calculating..\n",
      "5, 17 calculating..\n",
      "5, 18 calculating..\n",
      "5, 19 calculating..\n",
      "5, 20 calculating..\n",
      "5, 21 calculating..\n",
      "5, 22 calculating..\n",
      "5, 23 calculating..\n",
      "5, 24 calculating..\n",
      "5, 25 calculating..\n",
      "5, 26 calculating..\n",
      "5, 27 calculating..\n",
      "5, 28 calculating..\n",
      "5, 29 calculating..\n",
      "6, 0 calculating..\n",
      "6, 1 calculating..\n",
      "6, 2 calculating..\n",
      "6, 3 calculating..\n",
      "6, 4 calculating..\n",
      "6, 5 calculating..\n",
      "6, 6 calculating..\n",
      "6, 7 calculating..\n",
      "6, 8 calculating..\n",
      "6, 9 calculating..\n",
      "6, 10 calculating..\n",
      "6, 11 calculating..\n",
      "6, 12 calculating..\n",
      "6, 13 calculating..\n",
      "6, 14 calculating..\n",
      "6, 15 calculating..\n",
      "6, 16 calculating..\n",
      "6, 17 calculating..\n",
      "6, 18 calculating..\n",
      "6, 19 calculating..\n",
      "6, 20 calculating..\n",
      "6, 21 calculating..\n",
      "6, 22 calculating..\n",
      "6, 23 calculating..\n",
      "6, 24 calculating..\n",
      "6, 25 calculating..\n",
      "6, 26 calculating..\n",
      "6, 27 calculating..\n",
      "6, 28 calculating..\n",
      "6, 29 calculating..\n",
      "7, 0 calculating..\n",
      "7, 1 calculating..\n",
      "7, 2 calculating..\n",
      "7, 3 calculating..\n",
      "7, 4 calculating..\n",
      "7, 5 calculating..\n",
      "7, 6 calculating..\n",
      "7, 7 calculating..\n",
      "7, 8 calculating..\n",
      "7, 9 calculating..\n",
      "7, 10 calculating..\n",
      "7, 11 calculating..\n",
      "7, 12 calculating..\n",
      "7, 13 calculating..\n",
      "7, 14 calculating..\n",
      "7, 15 calculating..\n",
      "7, 16 calculating..\n",
      "7, 17 calculating..\n",
      "7, 18 calculating..\n",
      "7, 19 calculating..\n",
      "7, 20 calculating..\n",
      "7, 21 calculating..\n",
      "7, 22 calculating..\n",
      "7, 23 calculating..\n",
      "7, 24 calculating..\n",
      "7, 25 calculating..\n",
      "7, 26 calculating..\n",
      "7, 27 calculating..\n",
      "7, 28 calculating..\n",
      "7, 29 calculating..\n",
      "8, 0 calculating..\n",
      "8, 1 calculating..\n",
      "8, 2 calculating..\n",
      "8, 3 calculating..\n",
      "8, 4 calculating..\n",
      "8, 5 calculating..\n",
      "8, 6 calculating..\n",
      "8, 7 calculating..\n",
      "8, 8 calculating..\n",
      "8, 9 calculating..\n",
      "8, 10 calculating..\n",
      "8, 11 calculating..\n",
      "8, 12 calculating..\n",
      "8, 13 calculating..\n",
      "8, 14 calculating..\n",
      "8, 15 calculating..\n",
      "8, 16 calculating..\n",
      "8, 17 calculating..\n",
      "8, 18 calculating..\n",
      "8, 19 calculating..\n",
      "8, 20 calculating..\n",
      "8, 21 calculating..\n",
      "8, 22 calculating..\n",
      "8, 23 calculating..\n",
      "8, 24 calculating..\n",
      "8, 25 calculating..\n",
      "8, 26 calculating..\n",
      "8, 27 calculating..\n",
      "8, 28 calculating..\n",
      "8, 29 calculating..\n",
      "9, 0 calculating..\n",
      "9, 1 calculating..\n",
      "9, 2 calculating..\n",
      "9, 3 calculating..\n",
      "9, 4 calculating..\n",
      "9, 5 calculating..\n",
      "9, 6 calculating..\n",
      "9, 7 calculating..\n",
      "9, 8 calculating..\n",
      "9, 9 calculating..\n",
      "9, 10 calculating..\n",
      "9, 11 calculating..\n",
      "9, 12 calculating..\n",
      "9, 13 calculating..\n",
      "9, 14 calculating..\n",
      "9, 15 calculating..\n",
      "9, 16 calculating..\n",
      "9, 17 calculating..\n",
      "9, 18 calculating..\n",
      "9, 19 calculating..\n",
      "9, 20 calculating..\n",
      "9, 21 calculating..\n",
      "9, 22 calculating..\n",
      "9, 23 calculating..\n",
      "9, 24 calculating..\n",
      "9, 25 calculating..\n",
      "9, 26 calculating..\n",
      "9, 27 calculating..\n",
      "9, 28 calculating..\n",
      "9, 29 calculating..\n",
      "10, 0 calculating..\n",
      "10, 1 calculating..\n",
      "10, 2 calculating..\n",
      "10, 3 calculating..\n",
      "10, 4 calculating..\n",
      "10, 5 calculating..\n",
      "10, 6 calculating..\n",
      "10, 7 calculating..\n",
      "10, 8 calculating..\n",
      "10, 9 calculating..\n",
      "10, 10 calculating..\n",
      "10, 11 calculating..\n",
      "10, 12 calculating..\n",
      "10, 13 calculating..\n",
      "10, 14 calculating..\n",
      "10, 15 calculating..\n",
      "10, 16 calculating..\n",
      "10, 17 calculating..\n",
      "10, 18 calculating..\n",
      "10, 19 calculating..\n",
      "10, 20 calculating..\n",
      "10, 21 calculating..\n",
      "10, 22 calculating..\n",
      "10, 23 calculating..\n",
      "10, 24 calculating..\n",
      "10, 25 calculating..\n",
      "10, 26 calculating..\n",
      "10, 27 calculating..\n",
      "10, 28 calculating..\n",
      "10, 29 calculating..\n",
      "11, 0 calculating..\n",
      "11, 1 calculating..\n",
      "11, 2 calculating..\n",
      "11, 3 calculating..\n",
      "11, 4 calculating..\n",
      "11, 5 calculating..\n",
      "11, 6 calculating..\n",
      "11, 7 calculating..\n",
      "11, 8 calculating..\n",
      "11, 9 calculating..\n",
      "11, 10 calculating..\n",
      "11, 11 calculating..\n",
      "11, 12 calculating..\n",
      "11, 13 calculating..\n",
      "11, 14 calculating..\n",
      "11, 15 calculating..\n",
      "11, 16 calculating..\n",
      "11, 17 calculating..\n",
      "11, 18 calculating..\n",
      "11, 19 calculating..\n",
      "11, 20 calculating..\n",
      "11, 21 calculating..\n",
      "11, 22 calculating..\n",
      "11, 23 calculating..\n",
      "11, 24 calculating..\n",
      "11, 25 calculating..\n",
      "11, 26 calculating..\n",
      "11, 27 calculating..\n",
      "11, 28 calculating..\n",
      "11, 29 calculating..\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "predicted_data = {}\n",
    "\n",
    "Th_alpha = 0.06\n",
    "Th_k = 0.06\n",
    "end_index = 3\n",
    "\n",
    "\n",
    "for exp in range(12):\n",
    "    predicted_exp = {}\n",
    "    for fov in range(30):\n",
    "        predicted_fov = []\n",
    "        print('{}, {} calculating..'.format(exp, fov))\n",
    "        error_num1 = 0\n",
    "        error_num2 = 0\n",
    "\n",
    "        for n in range(len(challenge_data[exp][fov][0])):\n",
    "\n",
    "            feature_alpha = tf.reshape(alpha_input[exp][fov][n],(1,1,191,1))\n",
    "            feature_k = tf.reshape(k_input[exp][fov][n],(1,1,191,1))\n",
    "                           \n",
    "            data = challenge_data[exp][fov][0][n]\n",
    "\n",
    "            predicted_n = final_submit(feature_alpha,feature_k, model_alpha, model_k, data, Th_alpha, Th_k,end_index)\n",
    "            predicted_fov.append(predicted_n)\n",
    "                    \n",
    "            \n",
    "            if predicted_n[-1] != len(challenge_data[exp][fov][0][n]):\n",
    "                error_num1 += 1\n",
    "            \n",
    "            elif int(len(predicted_n)-1)%4 != 0:\n",
    "                error_num2 += 1\n",
    "                \n",
    "            \n",
    "        if error_num1 != 0:\n",
    "            print('{} - error!'.format('not match data_length'))\n",
    "            \n",
    "        elif error_num2 != 0:\n",
    "            print('{} - error!'.format('not match data_shape'))\n",
    "  \n",
    "            \n",
    "        predicted_exp[fov] = predicted_fov\n",
    "    predicted_data[exp] = predicted_exp\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81960b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write predicted_data\n",
    "\n",
    "for exp in range(len(challenge_data)):\n",
    "    for fov in range(30):\n",
    "   \n",
    "        file_name = 'predict_data/exp_{}/fov_{}.txt'.format(exp,fov)\n",
    "\n",
    "        text = '\\n'.join([','.join(map(str, row)) for row in predicted_data[exp][fov]])\n",
    "\n",
    "        with open(file_name, 'w') as f:\n",
    "            f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
